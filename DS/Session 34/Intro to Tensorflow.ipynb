{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.Session()\n",
    "sess1.run(c)\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # __enter__ & __exit__\n",
    "    res = sess.run(b)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "sess3 = tf.Session()\n",
    "# print(c.eval(session=sess3))\n",
    "with sess3.as_default():\n",
    "    print(c.eval())\n",
    "sess3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = tf.Variable(10, dtype=\"float\")\n",
    "var2 = tf.Variable(20, dtype=\"float\")\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # __enter__ & __exit__\n",
    "#     var1.initializer.run()\n",
    "#     var2.initializer.run()\n",
    "    init.run()\n",
    "    res = sess.run(var1+var2)\n",
    "    print(res)\n",
    "    \n",
    "    var1.assign(res).eval()\n",
    "    res = sess.run(var1+var2)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "sess2 = tf.Session()\n",
    "sess2.run(init)\n",
    "res = sess2.run(var1+var2)\n",
    "\n",
    "sess2.run(var1.assign(res))\n",
    "res = sess2.run(var1+var2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess2.run(var1.assign(res))\n",
    "res = sess2.run(var1+var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = tf.placeholder(dtype=\"float\")\n",
    "val3 = tf.placeholder(dtype=\"int32\")\n",
    "val2 = tf.constant(10.0) + val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.9\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(val2, feed_dict={val1:29.9}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = make_blobs(n_features=2, centers=2)\n",
    "X_data = np.hstack([X_data, np.ones((X_data.shape[0], 1))])\n",
    "y_data = y_data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 3))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "w = tf.Variable(np.random.randn(3, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.sigmoid(tf.matmul(X, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(-1 * (y * tf.log(y_pred) + (1-y)*tf.log(1-y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_op = tf.gradients(loss, [w]) # [dl/dw, dl/dx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18070264\n",
      "Loss: 0.1599594\n",
      "Loss: 0.14450234\n",
      "Loss: 0.13248774\n",
      "Loss: 0.122844994\n",
      "Loss: 0.11491109\n",
      "Loss: 0.10824642\n",
      "Loss: 0.10255279\n",
      "Loss: 0.0976198\n",
      "Loss: 0.093293995\n",
      "Loss: 0.0894592\n",
      "Loss: 0.086031675\n",
      "Loss: 0.08294007\n",
      "Loss: 0.08013424\n",
      "Loss: 0.07757137\n",
      "Loss: 0.07521619\n",
      "Loss: 0.07304333\n",
      "Loss: 0.07102863\n",
      "Loss: 0.069152735\n",
      "Loss: 0.06739947\n",
      "Loss: 0.06575737\n",
      "Loss: 0.06421167\n",
      "Loss: 0.06275605\n",
      "Loss: 0.06137891\n",
      "Loss: 0.06007563\n",
      "Loss: 0.05883742\n",
      "Loss: 0.057660803\n",
      "Loss: 0.05653835\n",
      "Loss: 0.05546762\n",
      "Loss: 0.05444328\n",
      "Loss: 0.053464074\n",
      "Loss: 0.052523952\n",
      "Loss: 0.05162179\n",
      "Loss: 0.050755363\n",
      "Loss: 0.049921807\n",
      "Loss: 0.04911873\n",
      "Loss: 0.048344575\n",
      "Loss: 0.04759832\n",
      "Loss: 0.046877466\n",
      "Loss: 0.046179853\n",
      "Loss: 0.045506194\n",
      "Loss: 0.044853922\n",
      "Loss: 0.044222265\n",
      "Loss: 0.043608703\n",
      "Loss: 0.043015037\n",
      "Loss: 0.04243875\n",
      "Loss: 0.041879132\n",
      "Loss: 0.04133516\n",
      "Loss: 0.04080702\n",
      "Loss: 0.040292196\n",
      "Loss: 0.03979207\n",
      "Loss: 0.039305437\n",
      "Loss: 0.038831517\n",
      "Loss: 0.038369134\n",
      "Loss: 0.037917797\n",
      "Loss: 0.03748025\n",
      "Loss: 0.037051663\n",
      "Loss: 0.036632933\n",
      "Loss: 0.036225244\n",
      "Loss: 0.03582604\n",
      "Loss: 0.03543752\n",
      "Loss: 0.035057124\n",
      "Loss: 0.034685325\n",
      "Loss: 0.03432194\n",
      "Loss: 0.03396716\n",
      "Loss: 0.033618525\n",
      "Loss: 0.03327837\n",
      "Loss: 0.032945614\n",
      "Loss: 0.032619193\n",
      "Loss: 0.032300647\n",
      "Loss: 0.031986944\n",
      "Loss: 0.031680282\n",
      "Loss: 0.031380307\n",
      "Loss: 0.03108588\n",
      "Loss: 0.030797306\n",
      "Loss: 0.030514164\n",
      "Loss: 0.030236395\n",
      "Loss: 0.02996364\n",
      "Loss: 0.029696621\n",
      "Loss: 0.029434074\n",
      "Loss: 0.029175885\n",
      "Loss: 0.028923547\n",
      "Loss: 0.028674968\n",
      "Loss: 0.02843057\n",
      "Loss: 0.028190171\n",
      "Loss: 0.027955918\n",
      "Loss: 0.027724413\n",
      "Loss: 0.027496131\n",
      "Loss: 0.027272442\n",
      "Loss: 0.027052695\n",
      "Loss: 0.026835397\n",
      "Loss: 0.026623946\n",
      "Loss: 0.026414823\n",
      "Loss: 0.02620928\n",
      "Loss: 0.026006423\n",
      "Loss: 0.025808163\n",
      "Loss: 0.025610084\n",
      "Loss: 0.025417792\n",
      "Loss: 0.025227172\n",
      "Loss: 0.02504049\n",
      "Loss: 0.024856197\n",
      "Loss: 0.024675183\n",
      "Loss: 0.024495069\n",
      "Loss: 0.024319667\n",
      "Loss: 0.024146413\n",
      "Loss: 0.023974894\n",
      "Loss: 0.023807429\n",
      "Loss: 0.023641156\n",
      "Loss: 0.023477273\n",
      "Loss: 0.023316314\n",
      "Loss: 0.023156967\n",
      "Loss: 0.023000246\n",
      "Loss: 0.022845732\n",
      "Loss: 0.022693425\n",
      "Loss: 0.022542076\n",
      "Loss: 0.022394065\n",
      "Loss: 0.02224731\n",
      "Loss: 0.022102943\n",
      "Loss: 0.021961259\n",
      "Loss: 0.021819696\n",
      "Loss: 0.021681473\n",
      "Loss: 0.021544801\n",
      "Loss: 0.02141016\n",
      "Loss: 0.021275282\n",
      "Loss: 0.021144576\n",
      "Loss: 0.021013932\n",
      "Loss: 0.020885857\n",
      "Loss: 0.02075915\n",
      "Loss: 0.0206337\n",
      "Loss: 0.020509858\n",
      "Loss: 0.020388285\n",
      "Loss: 0.020267725\n",
      "Loss: 0.020147288\n",
      "Loss: 0.02002989\n",
      "Loss: 0.019914225\n",
      "Loss: 0.019798739\n",
      "Loss: 0.01968528\n",
      "Loss: 0.019572357\n",
      "Loss: 0.019461883\n",
      "Loss: 0.01935278\n",
      "Loss: 0.019244216\n",
      "Loss: 0.019137023\n",
      "Loss: 0.019030845\n",
      "Loss: 0.018925918\n",
      "Loss: 0.01882165\n",
      "Loss: 0.01871947\n",
      "Loss: 0.0186186\n",
      "Loss: 0.018518746\n",
      "Loss: 0.018420206\n",
      "Loss: 0.018322082\n",
      "Loss: 0.018224435\n",
      "Loss: 0.018128935\n",
      "Loss: 0.018033916\n",
      "Loss: 0.017940508\n",
      "Loss: 0.017847216\n",
      "Loss: 0.017755536\n",
      "Loss: 0.017664572\n",
      "Loss: 0.017574923\n",
      "Loss: 0.017486345\n",
      "Loss: 0.017398601\n",
      "Loss: 0.017310264\n",
      "Loss: 0.017224789\n",
      "Loss: 0.017139077\n",
      "Loss: 0.017054854\n",
      "Loss: 0.016971406\n",
      "Loss: 0.01688826\n",
      "Loss: 0.016806187\n",
      "Loss: 0.01672489\n",
      "Loss: 0.0166452\n",
      "Loss: 0.01656617\n",
      "Loss: 0.016486363\n",
      "Loss: 0.016408049\n",
      "Loss: 0.016330212\n",
      "Loss: 0.01625494\n",
      "Loss: 0.016178949\n",
      "Loss: 0.016102903\n",
      "Loss: 0.016029896\n",
      "Loss: 0.015956236\n",
      "Loss: 0.015882812\n",
      "Loss: 0.01581088\n",
      "Loss: 0.015739188\n",
      "Loss: 0.015667675\n",
      "Loss: 0.015597711\n",
      "Loss: 0.015528702\n",
      "Loss: 0.015459217\n",
      "Loss: 0.015390688\n",
      "Loss: 0.015322694\n",
      "Loss: 0.015255534\n",
      "Loss: 0.01518915\n",
      "Loss: 0.015123662\n",
      "Loss: 0.015057697\n",
      "Loss: 0.014993939\n",
      "Loss: 0.014929346\n",
      "Loss: 0.01486511\n",
      "Loss: 0.014802485\n",
      "Loss: 0.014739741\n",
      "Loss: 0.014677951\n",
      "Loss: 0.014615983\n",
      "Loss: 0.014555626\n",
      "Loss: 0.014495505\n",
      "Loss: 0.01443473\n",
      "Loss: 0.014376042\n",
      "Loss: 0.014316818\n",
      "Loss: 0.014258786\n",
      "Loss: 0.014200039\n",
      "Loss: 0.014142546\n",
      "Loss: 0.014085648\n",
      "Loss: 0.014029525\n",
      "Loss: 0.013973881\n",
      "Loss: 0.013917579\n",
      "Loss: 0.0138624115\n",
      "Loss: 0.013808139\n",
      "Loss: 0.013754103\n",
      "Loss: 0.013699831\n",
      "Loss: 0.013645975\n",
      "Loss: 0.0135934325\n",
      "Loss: 0.013541485\n",
      "Loss: 0.01348936\n",
      "Loss: 0.013437771\n",
      "Loss: 0.013386302\n",
      "Loss: 0.013335131\n",
      "Loss: 0.013284735\n",
      "Loss: 0.013234698\n",
      "Loss: 0.013184064\n",
      "Loss: 0.013135041\n",
      "Loss: 0.013086315\n",
      "Loss: 0.013037054\n",
      "Loss: 0.012989938\n",
      "Loss: 0.012941572\n",
      "Loss: 0.012894038\n",
      "Loss: 0.012846865\n",
      "Loss: 0.012801002\n",
      "Loss: 0.01275359\n",
      "Loss: 0.012708086\n",
      "Loss: 0.012661805\n",
      "Loss: 0.012616182\n",
      "Loss: 0.012571692\n",
      "Loss: 0.012526487\n",
      "Loss: 0.012481757\n",
      "Loss: 0.012438282\n",
      "Loss: 0.012393315\n",
      "Loss: 0.01235145\n",
      "Loss: 0.012307436\n",
      "Loss: 0.012264617\n",
      "Loss: 0.01222287\n",
      "Loss: 0.012180229\n",
      "Loss: 0.01213765\n",
      "Loss: 0.012096081\n",
      "Loss: 0.012055051\n",
      "Loss: 0.0120142\n",
      "Loss: 0.011972931\n",
      "Loss: 0.0119325565\n",
      "Loss: 0.011892003\n",
      "Loss: 0.01185306\n",
      "Loss: 0.011812866\n",
      "Loss: 0.011773862\n",
      "Loss: 0.011734742\n",
      "Loss: 0.011694964\n",
      "Loss: 0.011657033\n",
      "Loss: 0.011618987\n",
      "Loss: 0.0115800435\n",
      "Loss: 0.0115425335\n",
      "Loss: 0.011504664\n",
      "Loss: 0.011468226\n",
      "Loss: 0.01143\n",
      "Loss: 0.011393085\n",
      "Loss: 0.01135778\n",
      "Loss: 0.011321105\n",
      "Loss: 0.011285323\n",
      "Loss: 0.011248767\n",
      "Loss: 0.011213761\n",
      "Loss: 0.011178219\n",
      "Loss: 0.011142975\n",
      "Loss: 0.011107789\n",
      "Loss: 0.011073916\n",
      "Loss: 0.011037839\n",
      "Loss: 0.011004262\n",
      "Loss: 0.010969675\n",
      "Loss: 0.010936816\n",
      "Loss: 0.010902764\n",
      "Loss: 0.010868952\n",
      "Loss: 0.010835318\n",
      "Loss: 0.010802757\n",
      "Loss: 0.010769779\n",
      "Loss: 0.010737994\n",
      "Loss: 0.010704897\n",
      "Loss: 0.010672991\n",
      "Loss: 0.010641326\n",
      "Loss: 0.0106099\n",
      "Loss: 0.010576863\n",
      "Loss: 0.010545673\n",
      "Loss: 0.010514187\n",
      "Loss: 0.010483535\n",
      "Loss: 0.010452943\n",
      "Loss: 0.01042229\n",
      "Loss: 0.010392115\n",
      "Loss: 0.010361883\n",
      "Loss: 0.01033135\n",
      "Loss: 0.010302009\n",
      "Loss: 0.01027118\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    n_epochs = 300\n",
    "    learning_rate = 0.01\n",
    "    for i in range(n_epochs):\n",
    "        loss_val = sess.run(loss, feed_dict={X:X_data, y:y_data})\n",
    "        print(\"Loss:\", loss_val)\n",
    "\n",
    "        grad_val = sess.run(grad_op, feed_dict={X:X_data, y:y_data})\n",
    "#         print(\"Gradient:\", grad_val[0])\n",
    "        sess.run(w.assign_sub(learning_rate*grad_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-52b857332ccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \"\"\"\n\u001b[1;32m-> 2439\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2441\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5426\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5427\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5428\u001b[1;33m       raise ValueError(\"Cannot execute operation using `run()`: No default \"\n\u001b[0m\u001b[0;32m   5429\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5430\u001b[0m                        \u001b[1;34m\"sess.as_default():` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`"
     ]
    }
   ],
   "source": [
    "init.run()\n",
    "loss.eval(feed_dict={X:X_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18070264\n",
      "Loss: 0.1599594\n",
      "Loss: 0.14450234\n",
      "Loss: 0.13248774\n",
      "Loss: 0.122844994\n",
      "Loss: 0.11491109\n",
      "Loss: 0.10824642\n",
      "Loss: 0.10255279\n",
      "Loss: 0.0976198\n",
      "Loss: 0.093293995\n",
      "Loss: 0.0894592\n",
      "Loss: 0.086031675\n",
      "Loss: 0.08294007\n",
      "Loss: 0.08013424\n",
      "Loss: 0.07757137\n",
      "Loss: 0.07521619\n",
      "Loss: 0.07304333\n",
      "Loss: 0.07102863\n",
      "Loss: 0.069152735\n",
      "Loss: 0.06739947\n",
      "Loss: 0.06575737\n",
      "Loss: 0.06421167\n",
      "Loss: 0.06275605\n",
      "Loss: 0.06137891\n",
      "Loss: 0.06007563\n",
      "Loss: 0.05883742\n",
      "Loss: 0.057660803\n",
      "Loss: 0.05653835\n",
      "Loss: 0.05546762\n",
      "Loss: 0.05444328\n",
      "Loss: 0.053464074\n",
      "Loss: 0.052523952\n",
      "Loss: 0.05162179\n",
      "Loss: 0.050755363\n",
      "Loss: 0.049921807\n",
      "Loss: 0.04911873\n",
      "Loss: 0.048344575\n",
      "Loss: 0.04759832\n",
      "Loss: 0.046877466\n",
      "Loss: 0.046179853\n",
      "Loss: 0.045506194\n",
      "Loss: 0.044853922\n",
      "Loss: 0.044222265\n",
      "Loss: 0.043608703\n",
      "Loss: 0.043015037\n",
      "Loss: 0.04243875\n",
      "Loss: 0.041879132\n",
      "Loss: 0.04133516\n",
      "Loss: 0.04080702\n",
      "Loss: 0.040292196\n",
      "Loss: 0.03979207\n",
      "Loss: 0.039305437\n",
      "Loss: 0.038831517\n",
      "Loss: 0.038369134\n",
      "Loss: 0.037917797\n",
      "Loss: 0.03748025\n",
      "Loss: 0.037051663\n",
      "Loss: 0.036632933\n",
      "Loss: 0.036225244\n",
      "Loss: 0.03582604\n",
      "Loss: 0.03543752\n",
      "Loss: 0.035057124\n",
      "Loss: 0.034685325\n",
      "Loss: 0.03432194\n",
      "Loss: 0.03396716\n",
      "Loss: 0.033618525\n",
      "Loss: 0.03327837\n",
      "Loss: 0.032945614\n",
      "Loss: 0.032619193\n",
      "Loss: 0.032300647\n",
      "Loss: 0.031986944\n",
      "Loss: 0.031680282\n",
      "Loss: 0.031380307\n",
      "Loss: 0.03108588\n",
      "Loss: 0.030797306\n",
      "Loss: 0.030514164\n",
      "Loss: 0.030236395\n",
      "Loss: 0.02996364\n",
      "Loss: 0.029696621\n",
      "Loss: 0.029434074\n",
      "Loss: 0.029175885\n",
      "Loss: 0.028923547\n",
      "Loss: 0.028674968\n",
      "Loss: 0.02843057\n",
      "Loss: 0.028190171\n",
      "Loss: 0.027955918\n",
      "Loss: 0.027724413\n",
      "Loss: 0.027496131\n",
      "Loss: 0.027272442\n",
      "Loss: 0.027052695\n",
      "Loss: 0.026835397\n",
      "Loss: 0.026623946\n",
      "Loss: 0.026414823\n",
      "Loss: 0.02620928\n",
      "Loss: 0.026006423\n",
      "Loss: 0.025808163\n",
      "Loss: 0.025610084\n",
      "Loss: 0.025417792\n",
      "Loss: 0.025227172\n",
      "Loss: 0.02504049\n",
      "Loss: 0.024856197\n",
      "Loss: 0.024675183\n",
      "Loss: 0.024495069\n",
      "Loss: 0.024319667\n",
      "Loss: 0.024146413\n",
      "Loss: 0.023974894\n",
      "Loss: 0.023807429\n",
      "Loss: 0.023641156\n",
      "Loss: 0.023477273\n",
      "Loss: 0.023316314\n",
      "Loss: 0.023156967\n",
      "Loss: 0.023000246\n",
      "Loss: 0.022845732\n",
      "Loss: 0.022693425\n",
      "Loss: 0.022542076\n",
      "Loss: 0.022394065\n",
      "Loss: 0.02224731\n",
      "Loss: 0.022102943\n",
      "Loss: 0.021961259\n",
      "Loss: 0.021819696\n",
      "Loss: 0.021681473\n",
      "Loss: 0.021544801\n",
      "Loss: 0.02141016\n",
      "Loss: 0.021275282\n",
      "Loss: 0.021144576\n",
      "Loss: 0.021013932\n",
      "Loss: 0.020885857\n",
      "Loss: 0.02075915\n",
      "Loss: 0.0206337\n",
      "Loss: 0.020509858\n",
      "Loss: 0.020388285\n",
      "Loss: 0.020267725\n",
      "Loss: 0.020147288\n",
      "Loss: 0.02002989\n",
      "Loss: 0.019914225\n",
      "Loss: 0.019798739\n",
      "Loss: 0.01968528\n",
      "Loss: 0.019572357\n",
      "Loss: 0.019461883\n",
      "Loss: 0.01935278\n",
      "Loss: 0.019244216\n",
      "Loss: 0.019137023\n",
      "Loss: 0.019030845\n",
      "Loss: 0.018925918\n",
      "Loss: 0.01882165\n",
      "Loss: 0.01871947\n",
      "Loss: 0.0186186\n",
      "Loss: 0.018518746\n",
      "Loss: 0.018420206\n",
      "Loss: 0.018322082\n",
      "Loss: 0.018224435\n",
      "Loss: 0.018128935\n",
      "Loss: 0.018033916\n",
      "Loss: 0.017940508\n",
      "Loss: 0.017847216\n",
      "Loss: 0.017755536\n",
      "Loss: 0.017664572\n",
      "Loss: 0.017574923\n",
      "Loss: 0.017486345\n",
      "Loss: 0.017398601\n",
      "Loss: 0.017310264\n",
      "Loss: 0.017224789\n",
      "Loss: 0.017139077\n",
      "Loss: 0.017054854\n",
      "Loss: 0.016971406\n",
      "Loss: 0.01688826\n",
      "Loss: 0.016806187\n",
      "Loss: 0.01672489\n",
      "Loss: 0.0166452\n",
      "Loss: 0.01656617\n",
      "Loss: 0.016486363\n",
      "Loss: 0.016408049\n",
      "Loss: 0.016330212\n",
      "Loss: 0.01625494\n",
      "Loss: 0.016178949\n",
      "Loss: 0.016102903\n",
      "Loss: 0.016029896\n",
      "Loss: 0.015956236\n",
      "Loss: 0.015882812\n",
      "Loss: 0.01581088\n",
      "Loss: 0.015739188\n",
      "Loss: 0.015667675\n",
      "Loss: 0.015597711\n",
      "Loss: 0.015528702\n",
      "Loss: 0.015459217\n",
      "Loss: 0.015390688\n",
      "Loss: 0.015322694\n",
      "Loss: 0.015255534\n",
      "Loss: 0.01518915\n",
      "Loss: 0.015123662\n",
      "Loss: 0.015057697\n",
      "Loss: 0.014993939\n",
      "Loss: 0.014929346\n",
      "Loss: 0.01486511\n",
      "Loss: 0.014802485\n",
      "Loss: 0.014739741\n",
      "Loss: 0.014677951\n",
      "Loss: 0.014615983\n",
      "Loss: 0.014555626\n",
      "Loss: 0.014495505\n",
      "Loss: 0.01443473\n",
      "Loss: 0.014376042\n",
      "Loss: 0.014316818\n",
      "Loss: 0.014258786\n",
      "Loss: 0.014200039\n",
      "Loss: 0.014142546\n",
      "Loss: 0.014085648\n",
      "Loss: 0.014029525\n",
      "Loss: 0.013973881\n",
      "Loss: 0.013917579\n",
      "Loss: 0.0138624115\n",
      "Loss: 0.013808139\n",
      "Loss: 0.013754103\n",
      "Loss: 0.013699831\n",
      "Loss: 0.013645975\n",
      "Loss: 0.0135934325\n",
      "Loss: 0.013541485\n",
      "Loss: 0.01348936\n",
      "Loss: 0.013437771\n",
      "Loss: 0.013386302\n",
      "Loss: 0.013335131\n",
      "Loss: 0.013284735\n",
      "Loss: 0.013234698\n",
      "Loss: 0.013184064\n",
      "Loss: 0.013135041\n",
      "Loss: 0.013086315\n",
      "Loss: 0.013037054\n",
      "Loss: 0.012989938\n",
      "Loss: 0.012941572\n",
      "Loss: 0.012894038\n",
      "Loss: 0.012846865\n",
      "Loss: 0.012801002\n",
      "Loss: 0.01275359\n",
      "Loss: 0.012708086\n",
      "Loss: 0.012661805\n",
      "Loss: 0.012616182\n",
      "Loss: 0.012571692\n",
      "Loss: 0.012526487\n",
      "Loss: 0.012481757\n",
      "Loss: 0.012438282\n",
      "Loss: 0.012393315\n",
      "Loss: 0.01235145\n",
      "Loss: 0.012307436\n",
      "Loss: 0.012264617\n",
      "Loss: 0.01222287\n",
      "Loss: 0.012180229\n",
      "Loss: 0.01213765\n",
      "Loss: 0.012096081\n",
      "Loss: 0.012055051\n",
      "Loss: 0.0120142\n",
      "Loss: 0.011972931\n",
      "Loss: 0.0119325565\n",
      "Loss: 0.011892003\n",
      "Loss: 0.01185306\n",
      "Loss: 0.011812866\n",
      "Loss: 0.011773862\n",
      "Loss: 0.011734742\n",
      "Loss: 0.011694964\n",
      "Loss: 0.011657033\n",
      "Loss: 0.011618987\n",
      "Loss: 0.0115800435\n",
      "Loss: 0.0115425335\n",
      "Loss: 0.011504664\n",
      "Loss: 0.011468226\n",
      "Loss: 0.01143\n",
      "Loss: 0.011393085\n",
      "Loss: 0.01135778\n",
      "Loss: 0.011321105\n",
      "Loss: 0.011285323\n",
      "Loss: 0.011248767\n",
      "Loss: 0.011213761\n",
      "Loss: 0.011178219\n",
      "Loss: 0.011142975\n",
      "Loss: 0.011107789\n",
      "Loss: 0.011073916\n",
      "Loss: 0.011037839\n",
      "Loss: 0.011004262\n",
      "Loss: 0.010969675\n",
      "Loss: 0.010936816\n",
      "Loss: 0.010902764\n",
      "Loss: 0.010868952\n",
      "Loss: 0.010835318\n",
      "Loss: 0.010802757\n",
      "Loss: 0.010769779\n",
      "Loss: 0.010737994\n",
      "Loss: 0.010704897\n",
      "Loss: 0.010672991\n",
      "Loss: 0.010641326\n",
      "Loss: 0.0106099\n",
      "Loss: 0.010576863\n",
      "Loss: 0.010545673\n",
      "Loss: 0.010514187\n",
      "Loss: 0.010483535\n",
      "Loss: 0.010452943\n",
      "Loss: 0.01042229\n",
      "Loss: 0.010392115\n",
      "Loss: 0.010361883\n",
      "Loss: 0.01033135\n",
      "Loss: 0.010302009\n",
      "Loss: 0.01027118\n"
     ]
    }
   ],
   "source": [
    "init.run()\n",
    "n_epochs = 300\n",
    "learning_rate = 0.01\n",
    "for i in range(n_epochs):\n",
    "    loss_val = loss.eval(feed_dict={X:X_data, y:y_data})\n",
    "    print(\"Loss:\", loss_val)\n",
    "\n",
    "    grad_val = grad_op[0].eval(feed_dict={X:X_data, y:y_data})\n",
    "#         print(\"Gradient:\", grad_val[0])\n",
    "    w.assign_sub(learning_rate*grad_val).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0102423765"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.eval(feed_dict={X:X_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(inputs=X, activation=\"sigmoid\", units=2)\n",
    "output = tf.layers.dense(inputs=layer1, activation=\"sigmoid\", units=1)\n",
    "\n",
    "nn_loss = tf.reduce_sum(-1 * (y * tf.log(output) + (1-y)*tf.log(1-output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(nn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "nn_sess = tf.Session()\n",
    "\n",
    "with nn_sess.as_default():\n",
    "    n_epochs = 100\n",
    "    tf.global_variables_initializer().run()\n",
    "    y_pred = output.eval(feed_dict={X:X_data, y:y_data})\n",
    "    print(\"Acc:\", (y_data == (y_pred > 0.5).astype(\"int\")).mean())\n",
    "    for i in range(n_epochs):\n",
    "        train_op.run(feed_dict={X:X_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = output.eval(session=nn_sess, feed_dict={X:X_data, y:y_data})\n",
    "print(\"Acc:\", (y_data == (y_pred > 0.5).astype(\"int\")).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(3, 1) dtype=float64_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(3, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(3, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(3, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(3, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(3, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_4/kernel:0' shape=(2, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "simple_save() got an unexpected keyword argument 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-ac577ad7e150>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimple_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./saved_model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: simple_save() got an unexpected keyword argument 'tag'"
     ]
    }
   ],
   "source": [
    "tf.saved_model.simple_save(export_dir=\"./saved_model\", session=nn_sess, inputs={'X':X, 'y':y}, outputs={'output': output})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
