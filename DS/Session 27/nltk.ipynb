{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "952603312201d9d1df6f1b6eb4a2044a9cb2cee3bbe4f29af3f4f86c434f8702"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in c:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.7.6-cp36-cp36m-win_amd64.whl (270 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (1.0.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\manu\\appdata\\roaming\\python\\python36\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.6.2 regex-2021.7.6 tqdm-4.61.2\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\manu\\appdata\\local\\programs\\python\\python36\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "source": [
    "### Data Collection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = brown.sents(categories=\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\""
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "\" \".join(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100554\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(data)):\n",
    "    c+=len(data[i])\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = brown.words(categories=\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100554"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "source": [
    "### Removal of Stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data = []\n",
    "for sent in data:\n",
    "    preprocess_sent = []\n",
    "    for word in sent:\n",
    "        if word.lower() not in stop_words:\n",
    "            preprocess_sent.append(word)\n",
    "    preprocess_data.append(preprocess_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Fulton County Grand Jury said Friday investigation Atlanta's recent primary election produced `` evidence '' irregularities took place .\""
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\" \".join(preprocess_data[0])"
   ]
  },
  {
   "source": [
    "### Regx Tokenization (Data-Cleaning)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Return',\n",
       " 'a',\n",
       " 'sentence-tokenized',\n",
       " 'copy',\n",
       " 'of',\n",
       " '*text*,using',\n",
       " \"NLTK's\",\n",
       " 'recommended',\n",
       " 'sentence',\n",
       " 'tokenizer']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "\"Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Return',\n",
       " 'a',\n",
       " 'sentence-tokenized',\n",
       " 'copy',\n",
       " 'of',\n",
       " '*',\n",
       " 'text',\n",
       " '*',\n",
       " ',',\n",
       " 'using',\n",
       " 'NLTK',\n",
       " \"'s\",\n",
       " 'recommended',\n",
       " 'sentence',\n",
       " 'tokenizer',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "word_tokenize(\"Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer.\",\n",
       " \"Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer.\"]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "sent_tokenize(\"Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer. Return a sentence-tokenized copy of *text*,using NLTK's recommended sentence tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"my name is manu my email id is manupillai308@gmail.com 99829991029 prime minister's home okay bye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regx = RegexpTokenizer(pattern=\"[a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'manu',\n",
       " 'my',\n",
       " 'email',\n",
       " 'id',\n",
       " 'is',\n",
       " 'manupillai',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 's',\n",
       " 'home',\n",
       " 'okay',\n",
       " 'bye']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "regx.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'investigation',\n",
       " 'Atlanta',\n",
       " 's',\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " 'evidence',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "regx.tokenize(\" \".join(preprocess_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preprocess_data)):\n",
    "    preprocess_data[i] = regx.tokenize(\" \".join(preprocess_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'investigation',\n",
       " 'Atlanta',\n",
       " 's',\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " 'evidence',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "preprocess_data[0]"
   ]
  },
  {
   "source": [
    "### Stemming & Lemmatization\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'establish'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "stemmer.stem(\"establishment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'establishment'"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "lemma.lemmatize(\"establishment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preprocess_data)):\n",
    "    preprocess_sent = []\n",
    "    for word in preprocess_data[i]:\n",
    "        preprocess_sent.append(stemmer.stem(word))\n",
    "    preprocess_data[i] = preprocess_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['fulton',\n",
       " 'counti',\n",
       " 'grand',\n",
       " 'juri',\n",
       " 'said',\n",
       " 'friday',\n",
       " 'investig',\n",
       " 'atlanta',\n",
       " 's',\n",
       " 'recent',\n",
       " 'primari',\n",
       " 'elect',\n",
       " 'produc',\n",
       " 'evid',\n",
       " 'irregular',\n",
       " 'took',\n",
       " 'place']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "preprocess_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preprocess_data)):\n",
    "    preprocess_data[i] = \" \".join(preprocess_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vectorizer = CountVectorizer(max_features=2000, binary=False, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=2000, ngram_range=(1, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "c_vectorizer.fit(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "len(c_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_count = c_vectorizer.transform(preprocess_data).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4623, 2000)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "x_data_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "x_data_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_tfidf = tfidf_vectorizer.fit_transform(preprocess_data).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_tfidf[0].max()"
   ]
  },
  {
   "source": [
    "### Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}