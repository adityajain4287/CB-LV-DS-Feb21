{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    \n",
    "    def __init__(self, ksize, stride, padding, activation, filters, input_size):\n",
    "        self.kernels = []\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.input_size = input_size\n",
    "        self.ksize = ksize\n",
    "        self.filters = filters\n",
    "        \n",
    "        self.bias = np.random.randn(filters).reshape(1, -1)\n",
    "        for i in range(filters):\n",
    "            self.kernels.append(np.random.randn(ksize, ksize, input_size[-1]))\n",
    "        self.activation = activation\n",
    "        \n",
    "    @staticmethod\n",
    "    def _rotate(inp):\n",
    "        assert len(inp.shape) == 4, f\"Shape mismatch, input map should have 4 dim, got {len(inp.shape)}\"\n",
    "\n",
    "        return np.flip(inp, axis=(1,2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _inside_pad(inp, pad_width):\n",
    "        assert len(inp.shape) == 4, f\"Shape mismatch, input map should have 4 dim, got {len(inp.shape)}\"\n",
    "        \n",
    "        if pad_width == 0:\n",
    "            return inp\n",
    "        ix = np.repeat(np.arange(1, inp.shape[1]), pad_width)\n",
    "\n",
    "        inp = np.insert(inp, ix, 0, axis=1)\n",
    "        return  np.insert(inp, ix, 0, axis=2)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad(inp, pad_width):\n",
    "        assert len(inp.shape) == 4, f\"Shape mismatch, input map should have 4 dim, got {len(inp.shape)}\"\n",
    "        if pad_width == 0:\n",
    "            return inp\n",
    "\n",
    "        return np.pad(inp, [(0, 0), (pad_width, pad_width), (pad_width, pad_width), (0,0)])\n",
    "\n",
    "    @staticmethod\n",
    "    def _convolution_op_w_kernel(inp, kernel, stride=1):\n",
    "        \n",
    "        assert len(inp.shape) == 4, f\"Shape mismatch, input map should have 4 dim, got {len(inp.shape)}\"\n",
    "        assert len(kernel.shape) == 4, f\"Shape mismatch, kernel should have 4 dim, got {len(kernel.shape)}\"\n",
    "        assert inp.shape[-1] == kernel.shape[-1], f\"Shape mismatch, input map should have same channel as kernel, got {inp.shape} & {kernel.shape}\"\n",
    "        assert kernel.shape[1] == kernel.shape[2], \"Non square kernels are not supported\"\n",
    "        assert (inp.shape[1] >= kernel.shape[0]) or (inp.shape[2] >= kernel.shape[1]), f\"Input map shape less than kernel, got {inp.shape[1:3]} for kernel {kernel.shape[:-1]}\"\n",
    "\n",
    "        kernel = Conv2D._rotate(kernel)\n",
    "\n",
    "        start_rloc = 0\n",
    "        end_rloc = kernel.shape[1]\n",
    "\n",
    "        oup = []\n",
    "\n",
    "        while end_rloc <= inp.shape[1]:\n",
    "\n",
    "            start_cloc = 0\n",
    "            end_cloc = kernel.shape[2]\n",
    "            output = []\n",
    "\n",
    "            while end_cloc <= inp.shape[2]:\n",
    "                conv = inp[:, start_rloc:end_rloc, start_cloc:end_cloc]*kernel\n",
    "                output.append(conv.sum(axis=(1,2,3)))\n",
    "\n",
    "                start_cloc += stride\n",
    "                end_cloc += stride\n",
    "\n",
    "            oup.append(output)\n",
    "\n",
    "            start_rloc += stride\n",
    "            end_rloc += stride        \n",
    "        \n",
    "        oup = np.expand_dims(oup, 0)\n",
    "        oup = np.transpose(oup, [3,1,2,0])\n",
    "        assert len(oup.shape) == 4, f\"Shape mismatch at convolution op, got {oup.shape}\"\n",
    "        \n",
    "        return oup\n",
    "    \n",
    "    def _convolution_op(self, inp, stride): \n",
    "        \n",
    "        feature_maps = []\n",
    "        for kernel in self.kernels:\n",
    "            oup = self._convolution_op_w_kernel(inp, np.expand_dims(kernel, 0), stride)\n",
    "            feature_maps.append(oup[...,0])\n",
    "        \n",
    "        return np.stack(feature_maps, axis=-1)\n",
    "    \n",
    "    def get_output_size(self):\n",
    "        m, n, k, p, s = self.input_size[0], self.input_size[1], self.ksize, self.padding, self.stride\n",
    "        return (m-k+2*p)//s + 1, (n-k+2*p)//s + 1, self.filters\n",
    "\n",
    "    def get_no_of_params(self):\n",
    "        return (self.ksize*self.ksize*self.input_size[-1]*self.filters) + self.filters\n",
    "\n",
    "    def eval(self, X):\n",
    "        out = self._convolution_op(X.T, self.stride) + self.bias\n",
    "        b, h, w, c = out.shape\n",
    "        a_out = self.activation(out.reshape(b, h*w*c).T)\n",
    "        return a_out.T.reshape(b, h, w, c).T\n",
    "\n",
    "    def grad_activation(self, X):\n",
    "        out = self._convolution_op(X.T, self.stride) + self.bias\n",
    "        b, h, w, c = out.shape\n",
    "        \n",
    "        da_dI = self.activation.grad_input(out.reshape(b, h*w*c).T)\n",
    "        da_dI = np.diagonal(da_dI, axis1=1, axis2=2)\n",
    "        \n",
    "        return da_dI.T.reshape(b, h, w, c)\n",
    "    \n",
    "        \n",
    "    def gradient_dict(self, output):\n",
    "        grad_ = {}\n",
    "        grad_[\"input\"] = self.get_input(output)\n",
    "        grad_[\"activation\"] = self.grad_activation(output)\n",
    "\n",
    "        return grad_\n",
    "    \n",
    "    def get_input(self, X):\n",
    "        out_h, out_w, _ = self.get_output_size()\n",
    "        h = (out_h-1)*self.stride-2*self.padding+self.ksize\n",
    "        w = (out_w-1)*self.stride-2*self.padding+self.ksize\n",
    "        return X.T[:, :h, :w, :]\n",
    "    \n",
    "    def backprop_grad(self, abcd, grad): # abcd -> grad_loss\n",
    "        pqrs = grad[\"activation\"]\n",
    "        \n",
    "        b, h, w, c = abcd.shape\n",
    "        \n",
    "        kernels = pqrs[:, :h, :w, :] * abcd\n",
    "        kernels = self._inside_pad(kernels, self.stride-1)\n",
    "        inps = grad[\"input\"]\n",
    "        grad_ws = []\n",
    "        \n",
    "        #### GRAD W---------------------------\n",
    "        for i in range(kernels.shape[-1]):\n",
    "            kernel = kernels[..., i]\n",
    "            grad_w = []\n",
    "            for j in range(inps.shape[-1]):\n",
    "                inp = inps[..., j]\n",
    "                oup = self._convolution_op_w_kernel(np.expand_dims(inp,-1), np.expand_dims(kernel, -1))\n",
    "                oup = self._rotate(oup).sum(axis=0)\n",
    "                grad_w.append(oup[...,0])\n",
    "            \n",
    "            grad_w = np.array(grad_w)\n",
    "            grad_ws.append(np.transpose(grad_w, [1,2,0]))\n",
    "        ### -----------------------------------\n",
    "        \n",
    "        #### GRAD I---------------------------\n",
    "        inp = self._pad(kernels, self.ksize-1)\n",
    "        kernels = self.kernels\n",
    "        \n",
    "        out_h, out_w, _ = self.get_output_size()\n",
    "        grad_shape = (grad[\"input\"].shape[0], (out_h-1)*self.stride-2*self.padding+self.ksize, (out_w-1)*self.stride-2*self.padding+self.ksize, self.input_size[-1])\n",
    "        grad_I = np.empty(grad_shape, dtype=\"float32\")\n",
    "        \n",
    "        for i in range(self.input_size[-1]):\n",
    "            kernel = np.dstack([kernels[j][...,i] for j in range(len(kernels))])\n",
    "            oup = self._convolution_op_w_kernel(inp, np.expand_dims(kernel, 0))\n",
    "            grad_I[..., i] = oup[...,0]\n",
    "            \n",
    "        ### -----------------------------------\n",
    "        \n",
    "        #### GRAD b---------------------------\n",
    "        grad_bs = np.sum(pqrs * abcd, axis=(1,2,0))\n",
    "\n",
    "        return grad_ws, grad_bs.reshape(1,-1), grad_I\n",
    "\n",
    "    def update(self, grad_w, grad_b, optimizer, method=\"minimize\"):\n",
    "        if method==\"minimize\":\n",
    "            self.bias = optimizer.minimize(self.bias, grad_b)\n",
    "            for i in range(len(self.kernels)):\n",
    "                self.kernels[i] = optimizer.minimize(self.kernels[i], grad_w[i])\n",
    "        else:\n",
    "            self.bias = optimizer.maximize(self.bias, grad_b)\n",
    "            for i in range(len(self.kernels)):\n",
    "                self.kernels[i] = optimizer.maximize(self.kernels[i], grad_w[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self, input_size):\n",
    "        self.h, self.w, self.c = input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return (self.h*self.w*self.c, 1)\n",
    "\n",
    "    def get_no_of_params(self):\n",
    "        return 0\n",
    "\n",
    "    def eval(self, X):\n",
    "        return X.T.reshape(-1, self.h*self.w*self.c).T\n",
    "\n",
    "    def grad_parameters(self, X):\n",
    "        pass\n",
    "    \n",
    "    def gradient_dict(self, output):\n",
    "        grad_ = {}\n",
    "        return grad_\n",
    "\n",
    "    def grad_input(self, X):\n",
    "        pass\n",
    "    \n",
    "    def backprop_grad(self, grad_loss, grad):\n",
    "        # m x 1 x self.h*self.w*self.c\n",
    "        return None, None, grad_loss[:, 0, :].reshape(-1, self.h, self.w, self.c)\n",
    "\n",
    "    def update(self, grad_w, grad_b, optimizer, method=\"minimize\"):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Manu\\Desktop\\CB-LV-DS-Feb21\\DS\\NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Sequential\n",
    "from layer import Dense\n",
    "from loss import BinaryCrossEntropy\n",
    "from activation import Sigmoid\n",
    "from optimizer import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(units=3, activation=Sigmoid(), input_size=2))\n",
    "# model.add(Dense(units=2, activation=Sigmoid(), input_size=3))\n",
    "# model.add(Dense(units=1, activation=Sigmoid(), input_size=2))\n",
    "# model.compile(BinaryCrossEntropy())\n",
    "# model.summary()\n",
    "\n",
    "# from sklearn.datasets import make_gaussian_quantiles\n",
    "# X, y = make_gaussian_quantiles(n_samples=200,n_classes=2)\n",
    "# y = y.reshape(-1,1)\n",
    "# print(\"Loss\", model.evaluate(X, y)[0])\n",
    "\n",
    "# model.fit(X, y, n_epochs=1000, batch_size=1, learning_rate=0.005, optimizer=GradientDescentOptimizer(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.vstack([x_train[y_train == 0][:2500], x_train[y_train == 1][:2500]]).reshape(-1,28,28,1)/255\n",
    "y_data = np.hstack([y_train[y_train == 0][:2500], y_train[y_train == 1][:2500]]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type    Output Shape      No. of parameters\n",
      "------------  --------------  -------------------\n",
      "Conv2D        (12, 12, 20)                    520\n",
      "Conv2D        (8, 8, 20)                    10020\n",
      "Conv2D        (6, 6, 15)                     2715\n",
      "Conv2D        (2, 2, 10)                     1360\n",
      "Flatten       (40, 1)                           0\n",
      "Dense         (1, 1)                           41\n",
      "Total No. of parameters: 14656\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D, ksize=5, stride=2, activation=Sigmoid(), input_size=(28,28,1), filters=20, padding=0)\n",
    "model.add(Conv2D, ksize=5, stride=1, activation=Sigmoid(), filters=20, padding=0)\n",
    "model.add(Conv2D, ksize=3, stride=1, activation=Sigmoid(), filters=15, padding=0)\n",
    "model.add(Conv2D, ksize=3, stride=3, activation=Sigmoid(), filters=10, padding=0)\n",
    "model.add(Flatten)\n",
    "model.add(Dense, units=1, activation=Sigmoid())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._eval(x_data[:30]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(BinaryCrossEntropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.461864130463653"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._eval_loss(x_data[:10], y_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1\n",
      "|-------------------------------------------------->| Loss: 0.3517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-834-e078efb8553a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.003\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\CB-LV-DS-Feb21\\DS\\NN\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, n_epochs, learning_rate, optimizer, batch_size, verbose)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_gradients_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_gradients_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CB-LV-DS-Feb21\\DS\\NN\\model.py\u001b[0m in \u001b[0;36mbackward_propagation\u001b[1;34m(self, outputs, gradients, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mgrad_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-799-91f1236486b7>\u001b[0m in \u001b[0;36mbackprop_grad\u001b[1;34m(self, abcd, grad)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 \u001b[0moup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op_w_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[0moup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[0mgrad_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-799-91f1236486b7>\u001b[0m in \u001b[0;36m_convolution_op_w_kernel\u001b[1;34m(inp, kernel, stride)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mend_rloc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0moup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0moup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Shape mismatch at convolution op, got {oup.shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\manu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \"\"\"\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_data, y_data, n_epochs=1, batch_size=1, learning_rate=0.003, optimizer=GradientDescentOptimizer(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.334762901722314"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._eval_loss(x_data[:10], y_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
